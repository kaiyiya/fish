"""
é±¼ç±»å›¾åƒè¯†åˆ«æ¨¡å‹è®­ç»ƒè„šæœ¬
ä½¿ç”¨é¢„è®­ç»ƒMobileNetV3è¿›è¡Œè¿ç§»å­¦ä¹ 
"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications import MobileNetV3Large
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import numpy as np
import os

# é…ç½®
IMG_SIZE = 224
BATCH_SIZE = 32
EPOCHS = 50
NUM_CLASSES = 20  # æ ¹æ®å®é™…é±¼ç±»ç§ç±»æ•°è°ƒæ•´
DATA_DIR = './data/fish_images'  # æ•°æ®é›†è·¯å¾„
MODEL_SAVE_PATH = './models/fish_classifier.h5'

def create_model(num_classes):
    """
    åˆ›å»ºåŸºäºMobileNetV3çš„è¿ç§»å­¦ä¹ æ¨¡å‹
    """
    # åŠ è½½é¢„è®­ç»ƒçš„MobileNetV3ï¼ˆåœ¨ImageNetä¸Šè®­ç»ƒï¼‰
    base_model = MobileNetV3Large(
        weights='imagenet',  # ä½¿ç”¨ImageNeté¢„è®­ç»ƒæƒé‡
        include_top=False,   # ä¸åŒ…å«é¡¶å±‚åˆ†ç±»å™¨
        input_shape=(IMG_SIZE, IMG_SIZE, 3),
        alpha=1.0,           # å®½åº¦ä¹˜æ•°
        minimalistic=False,
        pooling=None
    )
    
    # å†»ç»“åŸºç¡€æ¨¡å‹çš„å‰å‡ å±‚ï¼ˆå¯é€‰ï¼‰
    # base_model.trainable = False  # å®Œå…¨å†»ç»“
    # æˆ–è€…åªå†»ç»“å‰Nå±‚
    for layer in base_model.layers[:-10]:  # åªè®­ç»ƒæœ€å10å±‚
        layer.trainable = False
    
    # æ„å»ºå®Œæ•´æ¨¡å‹
    model = keras.Sequential([
        base_model,
        GlobalAveragePooling2D(),
        Dense(512, activation='relu'),
        Dropout(0.5),
        Dense(256, activation='relu'),
        Dropout(0.3),
        Dense(num_classes, activation='softmax')
    ])
    
    # ç¼–è¯‘æ¨¡å‹
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.0001),
        loss='categorical_crossentropy',
        metrics=['accuracy', 'top_3_accuracy']
    )
    
    return model

def prepare_data(data_dir):
    """
    å‡†å¤‡è®­ç»ƒæ•°æ®
    """
    # æ•°æ®å¢å¼ºé…ç½®
    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest',
        validation_split=0.2  # 20%ä½œä¸ºéªŒè¯é›†
    )
    
    # éªŒè¯æ•°æ®ç”Ÿæˆå™¨ï¼ˆä¸åšå¢å¼ºï¼‰
    val_datagen = ImageDataGenerator(
        rescale=1./255,
        validation_split=0.2
    )
    
    # è®­ç»ƒæ•°æ®ç”Ÿæˆå™¨
    train_generator = train_datagen.flow_from_directory(
        data_dir,
        target_size=(IMG_SIZE, IMG_SIZE),
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        subset='training',
        shuffle=True
    )
    
    # éªŒè¯æ•°æ®ç”Ÿæˆå™¨
    val_generator = val_datagen.flow_from_directory(
        data_dir,
        target_size=(IMG_SIZE, IMG_SIZE),
        batch_size=BATCH_SIZE,
        class_mode='categorical',
        subset='validation',
        shuffle=False
    )
    
    return train_generator, val_generator

def train():
    """
    è®­ç»ƒæ¨¡å‹
    """
    print("ğŸš€ å¼€å§‹è®­ç»ƒé±¼ç±»è¯†åˆ«æ¨¡å‹...")
    
    # å‡†å¤‡æ•°æ®
    print("ğŸ“ å‡†å¤‡æ•°æ®é›†...")
    train_gen, val_gen = prepare_data(DATA_DIR)
    
    # è·å–ç±»åˆ«æ•°
    num_classes = len(train_gen.class_indices)
    print(f"ğŸ“Š æ£€æµ‹åˆ° {num_classes} ä¸ªé±¼ç±»ç±»åˆ«")
    print(f"ç±»åˆ«æ˜ å°„: {train_gen.class_indices}")
    
    # åˆ›å»ºæ¨¡å‹
    print("ğŸ—ï¸  æ„å»ºæ¨¡å‹...")
    model = create_model(num_classes)
    model.summary()
    
    # å›è°ƒå‡½æ•°
    callbacks = [
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        ModelCheckpoint(
            MODEL_SAVE_PATH,
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        ),
        # æ—©åœ
        EarlyStopping(
            monitor='val_loss',
            patience=10,
            restore_best_weights=True,
            verbose=1
        ),
        # å­¦ä¹ ç‡è°ƒæ•´
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=5,
            min_lr=0.00001,
            verbose=1
        )
    ]
    
    # è®­ç»ƒæ¨¡å‹
    print("ğŸ¯ å¼€å§‹è®­ç»ƒ...")
    history = model.fit(
        train_gen,
        epochs=EPOCHS,
        validation_data=val_gen,
        callbacks=callbacks,
        verbose=1
    )
    
    print(f"âœ… è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åˆ°: {MODEL_SAVE_PATH}")
    
    # ä¿å­˜è®­ç»ƒå†å²
    import json
    with open('./models/training_history.json', 'w') as f:
        json.dump(history.history, f)
    
    # è¯„ä¼°æ¨¡å‹
    print("\nğŸ“ˆ è¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    val_loss, val_acc, val_top3_acc = model.evaluate(val_gen, verbose=1)
    print(f"éªŒè¯é›†å‡†ç¡®ç‡: {val_acc:.4f}")
    print(f"éªŒè¯é›†Top-3å‡†ç¡®ç‡: {val_top3_acc:.4f}")
    
    return model, history

def convert_to_tensorflowjs(model_path, output_path):
    """
    å°†æ¨¡å‹è½¬æ¢ä¸ºTensorFlow.jsæ ¼å¼ï¼ˆç”¨äºå‰ç«¯éƒ¨ç½²ï¼‰
    """
    import tensorflowjs as tfjs
    
    print(f"ğŸ”„ è½¬æ¢æ¨¡å‹ä¸ºTensorFlow.jsæ ¼å¼...")
    tfjs.converters.save_keras_model(
        keras.models.load_model(model_path),
        output_path
    )
    print(f"âœ… æ¨¡å‹å·²è½¬æ¢ä¸ºTensorFlow.jsæ ¼å¼: {output_path}")

def convert_to_onnx(model_path, output_path):
    """
    å°†æ¨¡å‹è½¬æ¢ä¸ºONNXæ ¼å¼ï¼ˆç”¨äºè·¨å¹³å°éƒ¨ç½²ï¼‰
    """
    import tf2onnx
    
    print(f"ğŸ”„ è½¬æ¢æ¨¡å‹ä¸ºONNXæ ¼å¼...")
    model = keras.models.load_model(model_path)
    
    spec = (tf.TensorSpec((None, IMG_SIZE, IMG_SIZE, 3), tf.float32, name="input"),)
    output_path_onnx = output_path.replace('.h5', '.onnx')
    model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=13)
    
    with open(output_path_onnx, "wb") as f:
        f.write(model_proto.SerializeToString())
    
    print(f"âœ… æ¨¡å‹å·²è½¬æ¢ä¸ºONNXæ ¼å¼: {output_path_onnx}")

if __name__ == '__main__':
    # è®¾ç½®GPUï¼ˆå¦‚æœæœ‰ï¼‰
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"âœ… ä½¿ç”¨GPU: {gpus}")
        except RuntimeError as e:
            print(f"âŒ GPUè®¾ç½®é”™è¯¯: {e}")
    
    # åˆ›å»ºæ¨¡å‹ä¿å­˜ç›®å½•
    os.makedirs('./models', exist_ok=True)
    
    # è®­ç»ƒæ¨¡å‹
    model, history = train()
    
    # å¯é€‰ï¼šè½¬æ¢ä¸ºå…¶ä»–æ ¼å¼
    # convert_to_tensorflowjs(MODEL_SAVE_PATH, './models/tfjs_model')
    # convert_to_onnx(MODEL_SAVE_PATH, MODEL_SAVE_PATH)
